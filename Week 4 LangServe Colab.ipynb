{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_b5R4KPgoJ0"
      },
      "source": [
        "#  QuanSkill Agentic AI: Week 4 — LCEL & APIs (Sections 4.1–4.9)\n",
        "Complete Colab notebook: LCEL graphs, Pydantic validation, mini-RAG, LangServe API, and reliability math.\n",
        "**Tip:** Run cells top-to-bottom. Toggle `DRY_RUN=True` to avoid real API calls."
      ],
      "id": "h_b5R4KPgoJ0"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tL5bDKf3goJ4",
        "outputId": "a9073935-c8e6-45f8-dd76-cfccbc5f925e"
      },
      "source": [
        "# Install required packages\n",
        "!pip -q install --upgrade langchain langchain-openai langchain-community langserve fastapi uvicorn[standard] faiss-cpu pydantic==2.* python-dotenv > /dev/null\n",
        "print('Dependencies installed.')"
      ],
      "id": "tL5bDKf3goJ4",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mDependencies installed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y langchain langchain-core langchain-openai langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jrpkee_rhT3o",
        "outputId": "68adf6d6-3b69-434d-9d86-b8b5bfb14412"
      },
      "id": "Jrpkee_rhT3o",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: langchain 1.0.2\n",
            "Uninstalling langchain-1.0.2:\n",
            "  Successfully uninstalled langchain-1.0.2\n",
            "Found existing installation: langchain-core 1.0.0\n",
            "Uninstalling langchain-core-1.0.0:\n",
            "  Successfully uninstalled langchain-core-1.0.0\n",
            "Found existing installation: langchain-openai 1.0.1\n",
            "Uninstalling langchain-openai-1.0.1:\n",
            "  Successfully uninstalled langchain-openai-1.0.1\n",
            "Found existing installation: langchain-community 0.4\n",
            "Uninstalling langchain-community-0.4:\n",
            "  Successfully uninstalled langchain-community-0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain==0.2.16 langchain-core==0.2.38 langchain-openai==0.1.22"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jf1w8h6xhw3_",
        "outputId": "6b675b1b-149e-4396-d51d-68ee9454c7ea"
      },
      "id": "Jf1w8h6xhw3_",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.4/396.4 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.0/52.0 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-classic 1.0.0 requires langchain-core<2.0.0,>=1.0.0, but you have langchain-core 0.2.38 which is incompatible.\n",
            "langchain-classic 1.0.0 requires langchain-text-splitters<2.0.0,>=1.0.0, but you have langchain-text-splitters 0.2.4 which is incompatible.\n",
            "langgraph-prebuilt 1.0.1 requires langchain-core>=0.3.67, but you have langchain-core 0.2.38 which is incompatible.\n",
            "langserve 0.3.3 requires langchain-core<2,>=0.3, but you have langchain-core 0.2.38 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChF0ptd8goJ6",
        "outputId": "c4f94046-4289-4174-d490-4e342407ff7e"
      },
      "source": [
        "# Environment setup\n",
        "import os\n",
        "DRY_RUN = True\n",
        "os.environ.setdefault('OPENAI_API_KEY', 'sk-your-key')\n",
        "os.environ.setdefault('LANGCHAIN_TRACING_V2', 'false')\n",
        "os.environ.setdefault('LANGCHAIN_PROJECT', 'week4_lcel_api')\n",
        "print('DRY_RUN:', DRY_RUN)"
      ],
      "id": "ChF0ptd8goJ6",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "DRY_RUN: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQQH4HFqgoJ6"
      },
      "source": [
        "## 4.1 — LCEL basic chain with mock LLM"
      ],
      "id": "yQQH4HFqgoJ6"
    },
    {
      "cell_type": "code",
      "source": [
        "import types, sys\n",
        "import langchain\n",
        "if not hasattr(langchain, \"debug\"):\n",
        "    langchain.debug = types.SimpleNamespace()\n",
        "sys.modules[\"langchain.debug\"] = langchain.debug"
      ],
      "metadata": {
        "id": "usAgtQ6oibv4"
      },
      "id": "usAgtQ6oibv4",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a59Dzy3rgoJ7",
        "outputId": "512454a8-b9c6-4195-cf51-5a10b09189af"
      },
      "source": [
        "# --- PATCH FOR LANGCHAIN DEBUG BUG ---\n",
        "import types, sys, langchain\n",
        "if not hasattr(langchain, \"debug\"):\n",
        "    langchain.debug = types.SimpleNamespace()\n",
        "sys.modules[\"langchain.debug\"] = langchain.debug\n",
        "\n",
        "# --- IMPORTS ---\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# --- FIXED MOCK LLM (FINAL VERSION) ---\n",
        "class MockLLM:\n",
        "    def invoke(self, msg):\n",
        "        \"\"\"\n",
        "        Handles all LangChain input types robustly.\n",
        "        \"\"\"\n",
        "        # --- Normalize to string ---\n",
        "        if hasattr(msg, \"to_string\"):          # For StringPromptValue\n",
        "            q = msg.to_string()\n",
        "        elif isinstance(msg, list):            # For chat messages\n",
        "            q = str(msg[-1].get(\"content\", msg[-1]))\n",
        "        elif isinstance(msg, dict):            # For single message dict\n",
        "            q = str(msg.get(\"content\", msg))\n",
        "        else:                                  # Fallback\n",
        "            q = str(msg)\n",
        "\n",
        "        # --- Ensure q is now a string ---\n",
        "        if not isinstance(q, str):\n",
        "            q = str(q)\n",
        "\n",
        "        # --- Return mock output safely ---\n",
        "        snippet = q[:70] if len(q) > 70 else q\n",
        "        return {\"content\": f\"[MOCK RESPONSE] {snippet} ...\"}\n",
        "\n",
        "\n",
        "# --- WRAP MOCK AS RUNNABLE ---\n",
        "def make_llm(dry=True):\n",
        "    if dry:\n",
        "        mock = MockLLM()\n",
        "        return RunnableLambda(lambda x: mock.invoke(x))\n",
        "    else:\n",
        "        return ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
        "\n",
        "# --- BUILD CHAIN ---\n",
        "DRY_RUN = True\n",
        "llm = make_llm(DRY_RUN)\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"Explain the idea of LCEL to a {audience} in 3 bullets.\"\n",
        ")\n",
        "\n",
        "chain = (\n",
        "    {\"audience\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | (lambda p: [{\"role\": \"user\", \"content\": p}])\n",
        "    | llm\n",
        ")\n",
        "\n",
        "# --- TEST RUN ---\n",
        "print(chain.invoke(\"platform engineers\")[\"content\"])"
      ],
      "id": "a59Dzy3rgoJ7",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[MOCK RESPONSE] text='Explain the idea of LCEL to a platform engineers in 3 bullets.' ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjbtScyRgoJ7"
      },
      "source": [
        "## 4.2 — Reliability & latency math"
      ],
      "id": "TjbtScyRgoJ7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIysoP79goJ8",
        "outputId": "2554810a-08a1-44b0-b401-ab7b687454e2"
      },
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class ReliabilityInputs:\n",
        "    N: int; E: int; T: int\n",
        "def reliability(r: ReliabilityInputs):\n",
        "    R_E = r.E / r.N; R_T = r.T / r.N; R = 1 - (R_E + R_T)\n",
        "    return {'R_E': R_E, 'R_T': R_T, 'R_total': R}\n",
        "\n",
        "print(reliability(ReliabilityInputs(N=200, E=5, T=4)))"
      ],
      "id": "oIysoP79goJ8",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'R_E': 0.025, 'R_T': 0.02, 'R_total': 0.955}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jxrz5pOegoJ8",
        "outputId": "87f199ce-80cd-4589-d06e-3365945cedb4"
      },
      "source": [
        "def latency_total(stages_ms: dict):\n",
        "    total = sum(stages_ms.values())\n",
        "    shares = {k: round(v/total, 4) for k,v in stages_ms.items()}\n",
        "    return total, shares\n",
        "\n",
        "stages = {'retrieval': 90, 'prompt': 60, 'llm': 240, 'validation': 30}\n",
        "print(latency_total(stages))"
      ],
      "id": "Jxrz5pOegoJ8",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(420, {'retrieval': 0.2143, 'prompt': 0.1429, 'llm': 0.5714, 'validation': 0.0714})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6JUHrV6goJ8"
      },
      "source": [
        "## 4.4 — Offline RAG chain"
      ],
      "id": "P6JUHrV6goJ8"
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall -y numpy scipy pandas opencv-python opencv-python-headless\n",
        "!rm -rf /root/.cache/pip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FRdHv1ok4WM",
        "outputId": "98f2567c-babb-4bea-a94e-301bf8819626"
      },
      "id": "0FRdHv1ok4WM",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: scipy 1.11.4\n",
            "Uninstalling scipy-1.11.4:\n",
            "  Successfully uninstalled scipy-1.11.4\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Found existing installation: opencv-python 4.12.0.88\n",
            "Uninstalling opencv-python-4.12.0.88:\n",
            "  Successfully uninstalled opencv-python-4.12.0.88\n",
            "Found existing installation: opencv-python-headless 4.8.0.74\n",
            "Uninstalling opencv-python-headless-4.8.0.74:\n",
            "  Successfully uninstalled opencv-python-headless-4.8.0.74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q numpy==1.26.4 scipy==1.11.4 pandas==2.2.2 opencv-python-headless==4.9.0.80"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ftg8QtClw4k",
        "outputId": "2a581efb-6908-4d86-e28b-ef7ca321e7b1"
      },
      "id": "9Ftg8QtClw4k",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.8/35.8 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.7/12.7 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.1.2 requires opencv-python>=3.4.8.29, which is not installed.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.1 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.11.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jaxlib 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires scipy>=1.13, but you have scipy 1.11.4 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "gradio 5.49.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.3 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np, scipy, pandas as pd, cv2\n",
        "print(\"NumPy:\", np.__version__)\n",
        "print(\"SciPy:\", scipy.__version__)\n",
        "print(\"Pandas:\", pd.__version__)\n",
        "print(\"OpenCV:\", cv2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GURW75Axl_u7",
        "outputId": "da27fcae-e0e5-442d-b828-48d863ab0cc7"
      },
      "id": "GURW75Axl_u7",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NumPy: 1.26.4\n",
            "SciPy: 1.11.4\n",
            "Pandas: 2.2.2\n",
            "OpenCV: 4.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZY2_Qn5kgoJ9",
        "outputId": "0be9353d-7500-4eb0-aad4-771eb428a32c"
      },
      "source": [
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.schema.runnable import RunnableLambda\n",
        "\n",
        "def embed(text: str) -> np.ndarray:\n",
        "    rng = np.random.default_rng(abs(hash(text)) % (2**32))\n",
        "    return rng.standard_normal(128).astype('float32')\n",
        "\n",
        "docs = [('id1', 'LCEL composes typed chains.'), ('id2', 'LangServe exposes REST APIs.'), ('id3', 'Pydantic validates schemas.')]\n",
        "matrix = np.vstack([embed(t) for _, t in docs])\n",
        "ids = [i for i, _ in docs]\n",
        "\n",
        "def search(q: str, k=2):\n",
        "    qv = embed(q)\n",
        "    sims = matrix @ qv / (np.linalg.norm(matrix, axis=1)*np.linalg.norm(qv)+1e-8)\n",
        "    order = np.argsort(-sims)[:k]\n",
        "    return [(ids[i], docs[i][1], float(sims[i])) for i in order]\n",
        "\n",
        "def retrieve_node(query: str):\n",
        "    return {'question': query, 'context': '\\n'.join([t for _,t,_ in search(query,3)])}\n",
        "\n",
        "retriever = RunnableLambda(retrieve_node)\n",
        "prompt = PromptTemplate.from_template('Use CONTEXT to answer:\\n{context}\\nQ: {question}')\n",
        "qa_chain = retriever | prompt | (lambda p: [{'role':'user','content': p}]) | llm\n",
        "print(getattr(qa_chain.invoke('What is LangServe?'), 'content', ''))"
      ],
      "id": "ZY2_Qn5kgoJ9",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EohO-jFRgoJ9"
      },
      "source": [
        "## 4.6 — Validation & KPI helpers"
      ],
      "id": "EohO-jFRgoJ9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6c_a0U4GgoJ-",
        "outputId": "06dbf8c4-23f3-4978-ad61-23b49c1f5d5e"
      },
      "source": [
        "from pydantic import BaseModel, PositiveInt, confloat\n",
        "class TravelPlan(BaseModel):\n",
        "    destination: str\n",
        "    days: PositiveInt\n",
        "    budget: confloat(gt=0)\n",
        "\n",
        "print(TravelPlan(destination='Tokyo', days=5, budget=900.0))"
      ],
      "id": "6c_a0U4GgoJ-",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "destination='Tokyo' days=5 budget=900.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xAsXU2GggoJ-",
        "outputId": "04d50189-2050-4895-c9c8-92525ae157a8"
      },
      "source": [
        "def compute_kpi(N, E, T):\n",
        "    r = reliability(ReliabilityInputs(N, E, T))\n",
        "    print(f\"R_total={r['R_total']:.4f}, R_E={r['R_E']:.4f}, R_T={r['R_T']:.4f}\")\n",
        "compute_kpi(400,6,2)"
      ],
      "id": "xAsXU2GggoJ-",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R_total=0.9800, R_E=0.0150, R_T=0.0050\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-a5l9SoDgoJ-"
      },
      "source": [
        "## 4.7 — Serve via LangServe (FastAPI)"
      ],
      "id": "-a5l9SoDgoJ-"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLfTbAYlgoJ-",
        "outputId": "2e9405e7-f798-4090-b771-0c1869f45874"
      },
      "source": [
        "# --- 4.7 Serve via LangServe (FastAPI, final stable version) ---\n",
        "\n",
        "from fastapi import FastAPI\n",
        "from langserve import add_routes\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# --- Define input and output schemas ---\n",
        "class Question(BaseModel):\n",
        "    question: str = Field(description=\"User query to be answered.\")\n",
        "\n",
        "class Answer(BaseModel):\n",
        "    summary: str = Field(description=\"Short answer summary\")\n",
        "    confidence: float = Field(description=\"Confidence score (0–1)\")\n",
        "\n",
        "# --- Build LCEL chain ---\n",
        "prompt = PromptTemplate.from_template(\"Answer the question clearly.\\nQ: {question}\\n\")\n",
        "\n",
        "def mock_llm_call(input_dict):\n",
        "    \"\"\"Mock LLM response to avoid dependency on OpenAI\"\"\"\n",
        "    q = input_dict[\"question\"]\n",
        "    return {\n",
        "        \"summary\": f\"[MOCK RESPONSE] {q[:60]} ...\",\n",
        "        \"confidence\": 0.99,\n",
        "    }\n",
        "\n",
        "typed_chain = RunnableLambda(mock_llm_call)\n",
        "\n",
        "# --- Create FastAPI app manually ---\n",
        "app = FastAPI(title=\"Week4 LCEL API\")\n",
        "\n",
        "@app.post(\"/rag/invoke\", response_model=Answer)\n",
        "def invoke_chain(query: Question):\n",
        "    \"\"\"Manually invoke the LCEL chain, avoiding LangServe schema introspection\"\"\"\n",
        "    return typed_chain.invoke(query.dict())\n",
        "\n",
        "print(\"Server ready. Run this to launch:\\n!uvicorn app:app --host 0.0.0.0 --port 8000\")"
      ],
      "id": "oLfTbAYlgoJ-",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Server ready. Run this to launch:\n",
            "!uvicorn app:app --host 0.0.0.0 --port 8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2FOehs8kgoJ_"
      },
      "source": [
        "## 4.8 — KPI quick report"
      ],
      "id": "2FOehs8kgoJ_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWxwR2X5goJ_",
        "outputId": "0e06c225-0806-49a4-fc4a-c8c8a0efd824"
      },
      "source": [
        "def kpi_report(N=1000, E=8, T=3, target=0.99):\n",
        "    r = reliability(ReliabilityInputs(N,E,T))\n",
        "    print(f'N={N} E={E} T={T} => R={r[\"R_total\"]:.4f}, meets {target}?', r['R_total']>=target)\n",
        "kpi_report()"
      ],
      "id": "jWxwR2X5goJ_",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N=1000 E=8 T=3 => R=0.9890, meets 0.99? False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2gsyQaQCgoJ_"
      },
      "source": [
        "## 4.9 — Reliability Stack Visualization"
      ],
      "id": "2gsyQaQCgoJ_"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "eOMKUU-ngoKA",
        "outputId": "f0ce7f11-996b-4399-d670-f1518f7ecc98"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "layers = ['LangSmith Monitoring','LangServe API','LCEL Logic','Validation (Pydantic)','Core LLM/Retriever']\n",
        "plt.figure(figsize=(7,5))\n",
        "for i, l in enumerate(layers):\n",
        "    plt.text(0.5, 0.9 - i*0.18, l, ha='center', va='center', bbox=dict(boxstyle='round', fc='white', ec='black'))\n",
        "plt.axis('off'); plt.show()"
      ],
      "id": "eOMKUU-ngoKA",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 700x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Optional: Extend to Production-ready API ---\n",
        "\n",
        "from fastapi.responses import StreamingResponse, JSONResponse\n",
        "import time, json\n",
        "\n",
        "@app.post(\"/rag/stream\")\n",
        "def stream_chain(query: Question):\n",
        "    \"\"\"Stream mock tokens one by one (useful for chat UI).\"\"\"\n",
        "    text = f\"[STREAM] Processing: {query.question}\"\n",
        "    def token_generator():\n",
        "        for ch in text:\n",
        "            yield ch\n",
        "            time.sleep(0.02)\n",
        "    return StreamingResponse(token_generator(), media_type=\"text/plain\")\n",
        "\n",
        "\n",
        "@app.post(\"/rag/batch\")\n",
        "def batch_chain(queries: list[Question]):\n",
        "    \"\"\"Batch endpoint for multiple queries.\"\"\"\n",
        "    outputs = [typed_chain.invoke(q.dict()) for q in queries]\n",
        "    return JSONResponse(content=outputs)\n",
        "\n",
        "\n",
        "@app.get(\"/health\")\n",
        "def health_check():\n",
        "    \"\"\"Basic health check.\"\"\"\n",
        "    return {\"status\": \"ok\", \"timestamp\": time.time()}"
      ],
      "metadata": {
        "id": "IS7rbgDooAdy"
      },
      "id": "IS7rbgDooAdy",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to run\n",
        "# !uvicorn app:app --host 0.0.0.0 --port 8000"
      ],
      "metadata": {
        "id": "-snTwVJ_oFQB"
      },
      "id": "-snTwVJ_oFQB",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "q_QF58IwoCXU"
      },
      "id": "q_QF58IwoCXU",
      "execution_count": null,
      "outputs": []
    }
  ]
}